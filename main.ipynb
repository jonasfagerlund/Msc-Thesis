{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_stata(\"./serrano/serrano_2024_Stata/serrano.dta\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['ORGNR', 'KOMORGNR', 'KOMNAMN', 'BSTYP', 'STATUS', 'REDTYP', 'BELKOD', 'UTDBEL', 'NTOMS', 'LAGERF', 'AKTARB', 'ROINTOV1', 'RAVAR', 'HANDVAR', 'EXTKOSOV', 'PERSKOS', 'AVSKRIV', 'JFRST1', 'RORKOOV1', 'RORRESUL', 'RESAND', 'RTEINKNC', 'RTEINEXT', 'RTEINOV', 'RTEKOKNC', 'RTEKOEXT', 'RTEKOOV', 'JFRSTFIN', 'RESEFIN', 'EXTRAINT', 'EXTRAKOS', 'KNCBDR', 'AGTSK', 'BSLDISP', 'SKATTER', 'MININTRR', 'RESAR', 'KOSALVAR', 'BRUTORES', 'FORSKO', 'ADMKO', 'FOUKO', 'JFRST2', 'ROINTOV2', 'RORKOOV2', 'EJINBET', 'FOUBAUTG', 'PATLIC', 'GOODWILL', 'IMANLOV', 'IMANLSU', 'BYGGMARK', 'MASK', 'INVENT', 'MASKINV', 'MATANLOV', 'MATANLSU', 'ANDKNC', 'LFORDKNC', 'LANDELAG', 'FIANLTOV', 'FIANLTSU', 'ANLTSU', 'PAGARB', 'LAGEROV', 'LAGERSU', 'KUNDFORD', 'KFORDKNC', 'KFORDOV', 'KFORDSU', 'KPLACSU', 'KABASU', 'OMSTGSU', 'TILLGSU', 'AKTIEKAP', 'OVERKURS', 'UPPSKR', 'OVRGBKAP', 'BALRES', 'KNCBDREL', 'AGTSKEL', 'RESARB', 'EKSU', 'OBESKRES', 'MININTR', 'AVSSU', 'LSKKRIN', 'LSKKNC', 'LSKOV', 'LSKSU', 'KSKKRIN', 'KSKLEV', 'KSKKNC', 'KSKOV', 'KSKSU', 'EKSKSU', 'RTENTO', 'ANTANST', 'LONLEDN', 'LONOV', 'SOCKOSTN', 'TANTLEDN', 'RESLONOV', 'AVGVED', 'AVSKSALV', 'AVSKFSG', 'AVSKADM', 'AVSKFOU', 'AVSKOV2', 'AVSKOSPC', 'INTFTG', 'INTFAST', 'SAKOV', 'SAKKOM', 'SAKSU', 'AGTSKV', 'ANSVFOV', 'ANSVFKOM', 'ANSVFSU', 'CHKRBEV', 'CHKRUTN', 'REVBER', 'BOLSTPRO', 'MODDTM', 'BSLSTART', 'BSLSLUT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "These filter should be thought through and written about in the methodology section.\n",
    "We want to avoid cherry-picking the data, but we also want to avoid including data that is not relevant to the study.\n",
    "\n",
    "We also want to avoid survuvalrship bias, i.e., we want to avoid including only the companies that have survived.\n",
    "\"\"\"\n",
    "\n",
    "filtered_df = df[(df['ser_year'] >= 2008) & # remove data before 2008\n",
    "                 (df['ser_jurform'] == 49) & # aktiebolag\n",
    "                 (df['ser_aktiv'] == 1) & # active companies\n",
    "                 (df['ser_ftgkategori'] == 30) & # private companies, i.e., not state-owned etc.\n",
    "                 (df['ser_stklf'] > 0) & # companies with at least 1 employee.\n",
    "                 (df['br09_tillgsu'] > 0) & # remove companies with no assets (there aren't many of those)\n",
    "                 (df['knc_kncfall'] == 1)] # only include independet companies, i.e., not subsidiaries or parent companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Growth Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/d0m27jy17d36rd2w_8y762cr0000gn/T/ipykernel_91882/2811014274.py:9: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  filtered_df['TURNOVER_GROWTH'] = filtered_df.groupby('ORGNR')['rr01_ntoms'].pct_change()\n",
      "/var/folders/pd/d0m27jy17d36rd2w_8y762cr0000gn/T/ipykernel_91882/2811014274.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  filtered_df['TURNOVER_GROWTH'] = filtered_df.groupby('ORGNR')['rr01_ntoms'].pct_change()\n",
      "/var/folders/pd/d0m27jy17d36rd2w_8y762cr0000gn/T/ipykernel_91882/2811014274.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['TURNOVER_GROWTH'] = filtered_df.groupby('ORGNR')['rr01_ntoms'].pct_change()\n",
      "/var/folders/pd/d0m27jy17d36rd2w_8y762cr0000gn/T/ipykernel_91882/2811014274.py:12: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  filtered_df['HIGH_GROWTH'] = filtered_df.groupby('ORGNR').apply(\n",
      "/var/folders/pd/d0m27jy17d36rd2w_8y762cr0000gn/T/ipykernel_91882/2811014274.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  filtered_df['HIGH_GROWTH'] = filtered_df.groupby('ORGNR').apply(\n",
      "/var/folders/pd/d0m27jy17d36rd2w_8y762cr0000gn/T/ipykernel_91882/2811014274.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['HIGH_GROWTH'] = filtered_df.groupby('ORGNR').apply(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Adding a variable for growth.\n",
    "Now the companies needs to be big in order to qualify as a high growth company which is a\n",
    "bit weird since then HGFs will be bigger companies than the other group which might not be ideal\n",
    "for making comparisons.\n",
    "\"\"\"\n",
    "\n",
    "# Calculate the annual growth rate for each company and add it as a new column\n",
    "filtered_df['TURNOVER_GROWTH'] = filtered_df.groupby('ORGNR')['rr01_ntoms'].pct_change()\n",
    "\n",
    "# Identify high-growth periods and create a new binary column\n",
    "filtered_df['HIGH_GROWTH'] = filtered_df.groupby('ORGNR').apply(\n",
    "    lambda x: ((x['TURNOVER_GROWTH'] > 0.20).rolling(window=3).sum() == 3) & \n",
    "              (x['ser_stklf'].iloc[0] in [3, 4, 5, 6, 7]) # only consider companies with at least 10 employees, based on size category\n",
    ").reset_index(level=0, drop=True).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add one industry per company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "There are a lot of columns in the dataset that is about the comapnies industry, a lot of different SNI codes.\n",
    "But we've decided to use the 'bransch_borsbransch_konv' column as the industry variable. Which is a conversion of the SNI codes\n",
    "to fewer branches.\n",
    "\n",
    "Some companies have changed industry over time, so we determine the most frequent industry for each company and add it as a new column\n",
    "to each row assicated with that company.\n",
    "\"\"\"\n",
    "\n",
    "# add one industry to all companies.\n",
    "dict_of_industries = {\n",
    "    10: 'Energy & Environment',\n",
    "    15: 'Materials',\n",
    "    20: 'Industrial goods',\n",
    "    22: 'Construction industry',\n",
    "    25: 'Shopping goods',\n",
    "    30: 'Convenience goods',\n",
    "    35: 'Health & Education',\n",
    "    40: 'Finance & Real estate',\n",
    "    45: 'IT & Electronics',\n",
    "    50: 'Telecom & Media',\n",
    "    60: 'Corporate services',\n",
    "    98: 'Other',\n",
    "    99: 'SNI07 missing'\n",
    "}\n",
    "\n",
    "# Determine the most frequent 'bransch_borsbransch_konv' value for each company\n",
    "most_frequent_industry = filtered_df.groupby('ORGNR')['bransch_borsbransch_konv'].agg(lambda x: x.mode()[0])\n",
    "\n",
    "# Map the most frequent 'bransch_borsbransch_konv' value to the corresponding industry name\n",
    "most_frequent_industry = most_frequent_industry.map(dict_of_industries)\n",
    "\n",
    "# Add the new 'INDUSTRY' column to the DataFrame\n",
    "filtered_df = filtered_df.merge(most_frequent_industry.rename('INDUSTRY'), on='ORGNR')\n",
    "\n",
    "# Filter out rows where the 'INDUSTRY' column is 'SNI07 missing' or 'Other'\n",
    "filtered_df = filtered_df[~filtered_df['INDUSTRY'].isin(['SNI07 missing', 'Other'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add variables from Vanacker & Manigart (2010)\n",
    "\n",
    "Adding variables for financing events, i.e., internal finance, debt, and equity. These are inspired from Vanacker & Manigart (2010)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/d0m27jy17d36rd2w_8y762cr0000gn/T/ipykernel_91882/3859428543.py:15: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  filtered_df['br10e_balres_pct_change'] = filtered_df.groupby('ORGNR')['br10e_balres'].pct_change()\n",
      "/var/folders/pd/d0m27jy17d36rd2w_8y762cr0000gn/T/ipykernel_91882/3859428543.py:35: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  filtered_df['combined_financial_debt_pct_change'] = filtered_df.groupby('ORGNR')['combined_financial_debt'].pct_change()\n",
      "/var/folders/pd/d0m27jy17d36rd2w_8y762cr0000gn/T/ipykernel_91882/3859428543.py:53: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  filtered_df['external_equity_pct_change'] = filtered_df.groupby('ORGNR')['external_equity'].pct_change()\n"
     ]
    }
   ],
   "source": [
    "# Dependent Variables\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Internal finance:\n",
    "\n",
    "\"When the net increase of retained earnings within a year exceeds 5% of total assets, we define this as an internal financing event.\"\n",
    "\n",
    "N.D., this is only retained earnings, not profit/loss of the current year, maybe that should be included too.\n",
    "Maybe not since that profit might be used for dividends so\n",
    "then maybe we list it as a internal finance thing but in reailty that money is not used for investments.\n",
    "\"\"\"\n",
    "\n",
    "# Calculate the percentage change in retained earnings from the previous year\n",
    "filtered_df['br10e_balres_pct_change'] = filtered_df.groupby('ORGNR')['br10e_balres'].pct_change()\n",
    "\n",
    "# Internal finance: 1 if the net increase in retained earnings exceeds 5% of total assets\n",
    "filtered_df['INTERNAL_FINANCE'] = (filtered_df['br10e_balres_pct_change'] > 0.05).astype(int)\n",
    "# filtered_df['INTERNAL_FINANCE'] = (filtered_df['br10e_balres_pct_change'] > filtered_df['br09_tillgsu'] * 0.05).astype(int)\n",
    "# ska inte vara %\n",
    "\n",
    "# Drop the temporary column\n",
    "filtered_df = filtered_df.drop(columns=['br10e_balres_pct_change'])\n",
    "\n",
    "\"\"\"\n",
    "Financing with debt:\n",
    "\n",
    "\"financial debt if there is a yearly net increase of outstanding financial debt (both short-term and long-term) that exceeds 5% of total assets.\"\n",
    "\"\"\"\n",
    "\n",
    "# Calculate the combined financial debt\n",
    "filtered_df['combined_financial_debt'] = filtered_df['br14_kskkrin'] + filtered_df['br16_lskkrin']\n",
    "\n",
    "# Calculate the percentage change in combined financial debt from the previous year\n",
    "filtered_df['combined_financial_debt_pct_change'] = filtered_df.groupby('ORGNR')['combined_financial_debt'].pct_change()\n",
    "\n",
    "# Financial debt dummy: 1 if the net increase in debt exceeds 5% of total assets\n",
    "filtered_df['FINANCIAL_DEBT'] = (filtered_df['combined_financial_debt_pct_change'] > 0.05).astype(int)\n",
    "\n",
    "# Drop the temporary column\n",
    "filtered_df = filtered_df.drop(columns=['combined_financial_debt_pct_change'])\n",
    "\n",
    "\"\"\"\n",
    "External equity:\n",
    "\n",
    "\"companies are coded as using new equity financing when there is a net increase in external equity of at least 5% of total assets.\"\n",
    "\"\"\"\n",
    "\n",
    "# Calculate the combined external equity (new share issues + share premium)\n",
    "filtered_df['external_equity'] = filtered_df['br10a_aktiekap'] + filtered_df['br10b_overkurs']\n",
    "\n",
    "# Calculate the percentage change in external equity from the previous year\n",
    "filtered_df['external_equity_pct_change'] = filtered_df.groupby('ORGNR')['external_equity'].pct_change()\n",
    "\n",
    "# External equity dummy: 1 if the net increase in external equity exceeds 5% of total assets\n",
    "filtered_df['EXTERNAL_EQUITY'] = (filtered_df['external_equity_pct_change'] > 0.05).astype(int)\n",
    "\n",
    "# Drop the temporary column\n",
    "filtered_df = filtered_df.drop(columns=['external_equity_pct_change'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Internal finance %  Financial debt %  External equity %\n",
      "ser_year                                                         \n",
      "2008.0              0.000000          0.000000           0.000000\n",
      "2009.0             44.536208         13.446251           1.020990\n",
      "2010.0             43.323048         13.045343           1.007320\n",
      "2011.0             45.100214         12.878572           0.746730\n",
      "2012.0             46.142779         12.342685           0.807837\n",
      "2013.0             43.846490         11.522622           0.746363\n",
      "2014.0             45.884252         11.214186           0.801013\n",
      "2015.0             46.756144         10.747891           0.811154\n",
      "2016.0             45.368373         11.027073           0.830549\n",
      "2017.0             44.609527         11.104876           0.738431\n",
      "2018.0             49.173297         10.815575           0.764148\n",
      "2019.0             48.959033         10.176730           0.746755\n",
      "2020.0             51.215839          8.878697           0.744791\n",
      "2021.0             50.658038          9.073462           0.825890\n",
      "2022.0             48.816277          8.573174           0.711178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/d0m27jy17d36rd2w_8y762cr0000gn/T/ipykernel_91882/1110289550.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  summary_table = filtered_df.groupby('ser_year').apply(lambda x: pd.Series({\n"
     ]
    }
   ],
   "source": [
    "# Group by 'ser_year' and calculate the percentage of firms with 1 in each column\n",
    "summary_table = filtered_df.groupby('ser_year').apply(lambda x: pd.Series({\n",
    "    'Internal finance %': (x['INTERNAL_FINANCE'].sum() / len(x)) * 100,\n",
    "    'Financial debt %': (x['FINANCIAL_DEBT'].sum() / len(x)) * 100,\n",
    "    'External equity %': (x['EXTERNAL_EQUITY'].sum() / len(x)) * 100\n",
    "}))\n",
    "\n",
    "# Display the summary table\n",
    "print(summary_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Independent Variables (lagging one year)\n",
    "\n",
    "\"\"\"\n",
    "Internal finance:\n",
    "\n",
    "\"As proxies for the amount of internal finance available within the venture,\n",
    "we use its profitability ratio, measured as earnings on total assets and\n",
    "the amount of cash and marketable securities on total assets.\n",
    "\n",
    "Have not included the second part yet, since I don't really know how to calculate it. Or what it is to be honest\n",
    "\n",
    "Finally, the pay-out ratio, measured as dividends on total assets, indicates lower internal finance.\"\n",
    " - I use another formula for pay ratio, dividends on net profit/loss.\n",
    "\"\"\"\n",
    "\n",
    "# ROA: Return on Assets (Earnings on Total Assets) - Lagged 1 Year\n",
    "filtered_df['ROA'] = filtered_df.groupby('ORGNR')['ny_avktokap'].shift(1)\n",
    "\n",
    "# Cash & Marketable Securities on Total Assets - Lagged 1 Year\n",
    "filtered_df['CASH_SEC_RATIO'] = filtered_df['br07_kplackaba'] / filtered_df['br09_tillgsu']\n",
    "filtered_df['CASH_SEC_RATIO'] = filtered_df.groupby('ORGNR')['CASH_SEC_RATIO'].shift(1)\n",
    "\n",
    "\n",
    "# PAYOUT_RATIO: Dividends on Net Profit - Avoiding Division by Zero\n",
    "filtered_df['PAYOUT_RATIO'] = np.where(\n",
    "    filtered_df['rr15_resar'] != 0,  # Only divide when Net Profit ≠ 0\n",
    "    filtered_df['rr00_utdbel'] / filtered_df['rr15_resar'],\n",
    "    0  # Otherwise, set to 0\n",
    ")\n",
    "\n",
    "# Lag PAYOUT_RATIO by 1 Year\n",
    "filtered_df['PAYOUT_RATIO'] = filtered_df.groupby('ORGNR')['PAYOUT_RATIO'].shift(1)\n",
    "\n",
    "\"\"\"\n",
    "\"Debt capacity is proxied by leverage and cash flow.\n",
    "\n",
    "Leverage is operationalized as a company’s debt ratio (financial debt on total assets).\n",
    "\n",
    "Furthermore, we include a variable indicating if debt is greater than\n",
    "total assets (negative stockholders’ equity dummy variable).\n",
    "\n",
    "Cash flow is operationalized by \n",
    "using the cash flow ratio (i.e., internally generated cash flow on total assets), indicating a\n",
    "company’s ability to support additional debt-related payments.\"\n",
    "\"\"\"\n",
    "\n",
    "# LEVERAGE: Total Debt / Total Assets - Lagged 1 Year\n",
    "filtered_df['LEVERAGE'] = filtered_df['combined_financial_debt'] / filtered_df['br09_tillgsu']\n",
    "filtered_df['LEVERAGE'] = filtered_df.groupby('ORGNR')['LEVERAGE'].shift(1)\n",
    "\n",
    "# CASH_FLOW_RATIO: Internally Generated Cash Flow - Lagged 1 Year\n",
    "filtered_df['CASH_FLOW_RATIO'] = (filtered_df['rr07_rorresul'] + filtered_df['rr05_avskriv'] - filtered_df['rr14_skatter'] - filtered_df['rr09_finkostn']) / filtered_df['br09_tillgsu']\n",
    "filtered_df['CASH_FLOW_RATIO'] = filtered_df.groupby('ORGNR')['CASH_FLOW_RATIO'].shift(1)\n",
    "\n",
    "# NEGATIVE STOCKHOLDERS EQUITY: 1 if Debt > Assets, else 0 - Lagged 1 Year\n",
    "filtered_df['NEGATIVE_STOCKHOLDERS_EQUITY'] = (filtered_df['combined_financial_debt'] > filtered_df['br09_tillgsu']).astype(int)\n",
    "filtered_df['NEGATIVE_STOCKHOLDERS_EQUITY'] = filtered_df.groupby('ORGNR')['NEGATIVE_STOCKHOLDERS_EQUITY'].shift(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control variables (lagging one year)\n",
    "\n",
    "\"\"\"\n",
    "Under the static trade-off theory tax shields, financial distress and agency costs are expected to determine financing decisions.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "We include two types of tax shields,\n",
    "\n",
    "debt tax shields (interests on total assets)\n",
    "\n",
    "and non-debt tax shields (depreciations on total assets).\n",
    "\"\"\"\n",
    "\n",
    "# Debt tax shields: Interest expenses / Total Assets - Lagged 1 Year\n",
    "filtered_df['DEBT_TAX_SHIELDS'] = filtered_df['rr09_finkostn'] / filtered_df['br09_tillgsu']\n",
    "filtered_df['DEBT_TAX_SHIELDS'] = filtered_df.groupby('ORGNR')['DEBT_TAX_SHIELDS'].shift(1)\n",
    "\n",
    "# Non-debt tax shields: Depreciation / Total Assets - Lagged 1 Year\n",
    "filtered_df['NON_DEBT_TAX_SHIELDS'] = filtered_df['rr05_avskriv'] / filtered_df['br09_tillgsu']\n",
    "filtered_df['NON_DEBT_TAX_SHIELDS'] = filtered_df.groupby('ORGNR')['NON_DEBT_TAX_SHIELDS'].shift(1)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The expected cost of financial distress depends on the probability of trouble and the value\n",
    "lost if trouble comes (Myers 1984). Our proxy for the probability of financial distress is\n",
    "the OJD score, which is similar to the Altman Z-statistic, but adapted to the\n",
    "Belgian context (Ooghe and Van Wymeersch 2003). A lower score indicates a higher risk of failure.\n",
    "\n",
    "Furthermore, we use asset structure operationalized as the ratio of property, plant and equipment\n",
    "to total assets as a proxy for the cost of financial distress. A lower ratio indicates a higher cost of financial distress\n",
    "\"\"\"\n",
    "\n",
    "# OJD score - need to find something similar in the dataset. SKIP FOR NOW\n",
    "\n",
    "# Asset Structure: Property, Plant & Equipment / Total Assets - Lagged 1 Year\n",
    "filtered_df['ASSET_STRUCTURE'] = filtered_df['br02_matanlsu'] / filtered_df['br09_tillgsu'] \n",
    "filtered_df['ASSET_STRUCTURE'] = filtered_df.groupby('ORGNR')['ASSET_STRUCTURE'].shift(1)\n",
    "\n",
    "\"\"\"\n",
    "Agency costs are particularly prevalent in a setting characterized by considerable future growth options.\n",
    "Firms generally engage in research and development to generate growth options (Titman and Wessels 1988).\n",
    "Consequently, we use the ratio of intangible assets on total assets to operationalize agency costs.\n",
    "\"\"\"\n",
    "\n",
    "# Agency Costs: Intangible Assets / Total Assets - Lagged 1 Year\n",
    "filtered_df['INTANGIBLE_ASSETS_RATIO'] = filtered_df['br01_imanlsu'] / filtered_df['br09_tillgsu']\n",
    "filtered_df['INTANGIBLE_ASSETS_RATIO'] = filtered_df.groupby('ORGNR')['INTANGIBLE_ASSETS_RATIO'].shift(1)\n",
    "\n",
    "\"\"\"\n",
    "Other general control variables, including organizational size (i.e., natural logarithm of total assets),\n",
    "\n",
    "previous debt financing (i.e., dummy variable equal to 1 if the venture acquired debt financing in the previous year, zero otherwise)\n",
    "\n",
    "and previous external equity financing (i.e., dummy variable equal to 1 if the venture acquired external equity in the previous year,\n",
    "zero otherwise) are included in the model. Furthermore, we included year and industry dummy variables in the analysis to\n",
    "control for time and industry effects.\n",
    "\"\"\"\n",
    "\n",
    "# Natural logarithm of total assets\n",
    "filtered_df['LOG_TOTAL_ASSETS'] = filtered_df['br09_tillgsu'].apply(lambda x: x if x <= 0 else np.log(x))\n",
    "\n",
    "filtered_df['LOG_TOTAL_ASSETS'] = filtered_df.groupby('ORGNR')['LOG_TOTAL_ASSETS'].shift(1)\n",
    "\n",
    "# Dummy variable indicating if the venture acquired debt financing in the previous year\n",
    "filtered_df['PREVIOUS_DEBT_FINANCING'] = filtered_df.groupby('ORGNR')['FINANCIAL_DEBT'].shift(1)\n",
    "\n",
    "# Convert NaN values (for first-year observations) to 0\n",
    "filtered_df['PREVIOUS_DEBT_FINANCING'] = filtered_df['PREVIOUS_DEBT_FINANCING'].fillna(0).astype(int)\n",
    "\n",
    "# Dummy variable indicating if the venture acquired external equity in the previous year\n",
    "filtered_df['PREVIOUS_EXTERNAL_EQUITY_FINANCING'] = filtered_df.groupby('ORGNR')['EXTERNAL_EQUITY'].shift(1)\n",
    "\n",
    "# Convert NaN values (for first-year observations) to 0\n",
    "filtered_df['PREVIOUS_EXTERNAL_EQUITY_FINANCING'] = filtered_df['PREVIOUS_EXTERNAL_EQUITY_FINANCING'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ORGNR                                 3935282\n",
       "ser_jurform                           3935282\n",
       "ser_year                              3935282\n",
       "ser_pnr                               3933791\n",
       "bransch_sni1                          2051149\n",
       "                                       ...   \n",
       "ASSET_STRUCTURE                       3400289\n",
       "INTANGIBLE_ASSETS_RATIO               3400288\n",
       "LOG_TOTAL_ASSETS                      3400322\n",
       "PREVIOUS_DEBT_FINANCING               3935282\n",
       "PREVIOUS_EXTERNAL_EQUITY_FINANCING    3935282\n",
       "Length: 197, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['ser_nystartat'].value_counts() # 272 491\n",
    "filtered_df.count() # 3935282"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Vanacker & Manigart (2010) tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in /opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages (0.14.4)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages (from statsmodels) (2.2.2)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages (from statsmodels) (1.15.1)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages (from statsmodels) (2.2.3)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages (from statsmodels) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages (from scikit-learn) (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install statsmodels\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages/statsmodels/discrete/discrete_model.py:2385: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "/opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages/statsmodels/discrete/discrete_model.py:2443: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q * linpred)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: inf\n",
      "         Iterations 12\n",
      "\n",
      "Internal Financing Model:\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:       INTERNAL_FINANCE   No. Observations:              3392981\n",
      "Model:                          Logit   Df Residuals:                  3392969\n",
      "Method:                           MLE   Df Model:                           11\n",
      "Date:                Mon, 10 Feb 2025   Pseudo R-squ.:                    -inf\n",
      "Time:                        13:06:59   Log-Likelihood:                   -inf\n",
      "converged:                       True   LL-Null:                   -2.3501e+06\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "======================================================================================================\n",
      "                                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Intercept                             -0.6123      0.006   -100.484      0.000      -0.624      -0.600\n",
      "ROA                                    0.9501      0.004    219.365      0.000       0.942       0.959\n",
      "CASH_SEC_RATIO                         0.3190      0.004     71.712      0.000       0.310       0.328\n",
      "PAYOUT_RATIO                          -0.0002   4.51e-05     -4.709      0.000      -0.000      -0.000\n",
      "LEVERAGE                              -0.0014      0.002     -0.803      0.422      -0.005       0.002\n",
      "NEGATIVE_STOCKHOLDERS_EQUITY           0.3645      0.021     17.117      0.000       0.323       0.406\n",
      "NON_DEBT_TAX_SHIELDS                  -0.1708      0.008    -22.335      0.000      -0.186      -0.156\n",
      "ASSET_STRUCTURE                        0.0721      0.005     13.821      0.000       0.062       0.082\n",
      "INTANGIBLE_ASSETS_RATIO               -0.0527      0.013     -3.932      0.000      -0.079      -0.026\n",
      "LOG_TOTAL_ASSETS                       0.0576      0.001     82.156      0.000       0.056       0.059\n",
      "PREVIOUS_DEBT_FINANCING                0.0586      0.004     15.882      0.000       0.051       0.066\n",
      "PREVIOUS_EXTERNAL_EQUITY_FINANCING     0.0347      0.013      2.693      0.007       0.009       0.060\n",
      "======================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages/statsmodels/discrete/discrete_model.py:2385: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n"
     ]
    }
   ],
   "source": [
    "# Define the variables needed for the regression\n",
    "regression_vars = [\n",
    "    'INTERNAL_FINANCE', 'ROA', 'CASH_SEC_RATIO', 'PAYOUT_RATIO',\n",
    "    'LEVERAGE', 'NEGATIVE_STOCKHOLDERS_EQUITY', 'NON_DEBT_TAX_SHIELDS', 'ASSET_STRUCTURE', \n",
    "    'INTANGIBLE_ASSETS_RATIO', 'LOG_TOTAL_ASSETS',\n",
    "    'PREVIOUS_DEBT_FINANCING', 'PREVIOUS_EXTERNAL_EQUITY_FINANCING'\n",
    "]\n",
    "\n",
    "# Removed CASH_FLOW_RATIO and DEBT_TAX_SHIELDS from the regression_vars list\n",
    "# VIF was higher than 10 for these variables, indicating multicollinearity\n",
    "\n",
    "# Create a new DataFrame with only the necessary variables\n",
    "df_regression = filtered_df[regression_vars].copy()\n",
    "\n",
    "# Drop or fill missing values\n",
    "df_regression = df_regression.dropna()  # OR df_regression.fillna(df_regression.mean())\n",
    "\n",
    "formula_internal = \"\"\"\n",
    "    INTERNAL_FINANCE ~ ROA + CASH_SEC_RATIO + PAYOUT_RATIO +\n",
    "    LEVERAGE + NEGATIVE_STOCKHOLDERS_EQUITY +\n",
    "    NON_DEBT_TAX_SHIELDS + ASSET_STRUCTURE + \n",
    "    INTANGIBLE_ASSETS_RATIO + LOG_TOTAL_ASSETS +\n",
    "    PREVIOUS_DEBT_FINANCING + PREVIOUS_EXTERNAL_EQUITY_FINANCING\n",
    "\"\"\"\n",
    "\n",
    "model_internal = smf.logit(formula=formula_internal, data=df_regression).fit()\n",
    "print(\"\\nInternal Financing Model:\")\n",
    "print(model_internal.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERNAL_FINANCE                           0\n",
      "ROA                                   555825\n",
      "CASH_SEC_RATIO                        555924\n",
      "PAYOUT_RATIO                          556583\n",
      "LEVERAGE                              562487\n",
      "NEGATIVE_STOCKHOLDERS_EQUITY          555825\n",
      "NON_DEBT_TAX_SHIELDS                  555825\n",
      "ASSET_STRUCTURE                       555860\n",
      "INTANGIBLE_ASSETS_RATIO               555861\n",
      "LOG_TOTAL_ASSETS                      555825\n",
      "PREVIOUS_DEBT_FINANCING                    0\n",
      "PREVIOUS_EXTERNAL_EQUITY_FINANCING         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_regression.isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.49248773e-01  3.17869732e-01 -2.34831743e-04 -1.28470452e-03\n",
      "   3.69447225e-01 -1.71879919e-01  8.35811073e-02 -5.49711078e-02\n",
      "   5.76996588e-02  6.14935857e-02  3.07760338e-02]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Drop or fill missing values\n",
    "df_regression = df_regression.dropna()  # OR df_regression.fillna(df_regression.mean())\n",
    "\n",
    "# Convert to NumPy arrays for sklearn\n",
    "X = df_regression.drop(columns=['INTERNAL_FINANCE']).values\n",
    "y = df_regression['INTERNAL_FINANCE'].values\n",
    "\n",
    "model = LogisticRegression(penalty='l2', solver='liblinear')\n",
    "model.fit(X, y)\n",
    "\n",
    "# Print coefficients\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages/statsmodels/discrete/discrete_model.py:2385: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "/opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages/statsmodels/discrete/discrete_model.py:2443: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q * linpred)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: inf\n",
      "         Iterations 14\n",
      "\n",
      "Internal Financing Model:\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:       INTERNAL_FINANCE   No. Observations:              3521631\n",
      "Model:                          Logit   Df Residuals:                  3521620\n",
      "Method:                           MLE   Df Model:                           10\n",
      "Date:                Sun, 09 Feb 2025   Pseudo R-squ.:                    -inf\n",
      "Time:                        18:45:36   Log-Likelihood:                   -inf\n",
      "converged:                       True   LL-Null:                   -2.4393e+06\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "======================================================================================================\n",
      "                                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Intercept                              0.0430      0.001     37.189      0.000       0.041       0.045\n",
      "ROA                                    5.4985      0.025    223.177      0.000       5.450       5.547\n",
      "CASH_SEC_RATIO                         0.0990      0.001     72.896      0.000       0.096       0.102\n",
      "PAYOUT_RATIO                          -0.0821      0.016     -5.185      0.000      -0.113      -0.051\n",
      "NEGATIVE_STOCKHOLDERS_EQUITY           0.3662      0.021     17.722      0.000       0.326       0.407\n",
      "NON_DEBT_TAX_SHIELDS                  -0.0727      0.003    -24.688      0.000      -0.078      -0.067\n",
      "ASSET_STRUCTURE                        0.0207      0.001     16.451      0.000       0.018       0.023\n",
      "INTANGIBLE_ASSETS_RATIO               -0.0048      0.001     -4.153      0.000      -0.007      -0.003\n",
      "LOG_TOTAL_ASSETS                       0.0985      0.001     83.978      0.000       0.096       0.101\n",
      "PREVIOUS_DEBT_FINANCING                0.0613      0.004     16.985      0.000       0.054       0.068\n",
      "PREVIOUS_EXTERNAL_EQUITY_FINANCING     0.0306      0.013      2.417      0.016       0.006       0.055\n",
      "======================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages/statsmodels/discrete/discrete_model.py:2385: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n"
     ]
    },
    {
     "ename": "PatsyError",
     "evalue": "Error evaluating factor: NameError: name 'FINANCIAL_DEBT' is not defined\n    FINANCIAL_DEBT ~ ROA + CASH_SEC_RATIO + PAYOUT_RATIO +     NEGATIVE_STOCKHOLDERS_EQUITY + NON_DEBT_TAX_SHIELDS +     ASSET_STRUCTURE + INTANGIBLE_ASSETS_RATIO + LOG_TOTAL_ASSETS +     PREVIOUS_DEBT_FINANCING + PREVIOUS_EXTERNAL_EQUITY_FINANCING\n    ^^^^^^^^^^^^^^",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages/patsy/compat.py:40\u001b[0m, in \u001b[0;36mcall_and_wrap_exc\u001b[0;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages/patsy/eval.py:179\u001b[0m, in \u001b[0;36mEvalEnvironment.eval\u001b[0;34m(self, expr, source_name, inner_namespace)\u001b[0m\n\u001b[1;32m    178\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcompile\u001b[39m(expr, source_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflags, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVarLookupDict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minner_namespace\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_namespaces\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:1\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FINANCIAL_DEBT' is not defined",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPatsyError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 57\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Debt Financing Model\u001b[39;00m\n\u001b[1;32m     51\u001b[0m formula_debt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124m    FINANCIAL_DEBT ~ ROA + CASH_SEC_RATIO + PAYOUT_RATIO +\u001b[39m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124m    NEGATIVE_STOCKHOLDERS_EQUITY + NON_DEBT_TAX_SHIELDS +\u001b[39m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124m    ASSET_STRUCTURE + INTANGIBLE_ASSETS_RATIO + LOG_TOTAL_ASSETS +\u001b[39m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124m    PREVIOUS_DEBT_FINANCING + PREVIOUS_EXTERNAL_EQUITY_FINANCING\u001b[39m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 57\u001b[0m model_debt \u001b[38;5;241m=\u001b[39m \u001b[43msmf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformula\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformula_debt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_regression\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfit()\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDebt Financing Model:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_debt\u001b[38;5;241m.\u001b[39msummary())\n",
      "File \u001b[0;32m/opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages/statsmodels/base/model.py:203\u001b[0m, in \u001b[0;36mModel.from_formula\u001b[0;34m(cls, formula, data, subset, drop_cols, *args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m:  \u001b[38;5;66;03m# with patsy it's drop or raise. let's raise.\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 203\u001b[0m tmp \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_formula_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformula\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m ((endog, exog), missing_idx, design_info) \u001b[38;5;241m=\u001b[39m tmp\n\u001b[1;32m    206\u001b[0m max_endog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_formula_max_endog\n",
      "File \u001b[0;32m/opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages/statsmodels/formula/formulatools.py:63\u001b[0m, in \u001b[0;36mhandle_formula_data\u001b[0;34m(Y, X, formula, depth, missing)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_util\u001b[38;5;241m.\u001b[39m_is_using_pandas(Y, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 63\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mdmatrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformula\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataframe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mNA_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m         result \u001b[38;5;241m=\u001b[39m dmatrices(formula, Y, depth, return_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataframe\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     67\u001b[0m                            NA_action\u001b[38;5;241m=\u001b[39mna_action)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages/patsy/highlevel.py:319\u001b[0m, in \u001b[0;36mdmatrices\u001b[0;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Construct two design matrices given a formula_like and data.\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \n\u001b[1;32m    311\u001b[0m \u001b[38;5;124;03mThis function is identical to :func:`dmatrix`, except that it requires\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03mSee :func:`dmatrix` for details.\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    318\u001b[0m eval_env \u001b[38;5;241m=\u001b[39m EvalEnvironment\u001b[38;5;241m.\u001b[39mcapture(eval_env, reference\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 319\u001b[0m (lhs, rhs) \u001b[38;5;241m=\u001b[39m \u001b[43m_do_highlevel_design\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mformula_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNA_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_type\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lhs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PatsyError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel is missing required outcome variables\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages/patsy/highlevel.py:164\u001b[0m, in \u001b[0;36m_do_highlevel_design\u001b[0;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdata_iter_maker\u001b[39m():\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28miter\u001b[39m([data])\n\u001b[0;32m--> 164\u001b[0m design_infos \u001b[38;5;241m=\u001b[39m \u001b[43m_try_incr_builders\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mformula_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_iter_maker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNA_action\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m design_infos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m build_design_matrices(\n\u001b[1;32m    169\u001b[0m         design_infos, data, NA_action\u001b[38;5;241m=\u001b[39mNA_action, return_type\u001b[38;5;241m=\u001b[39mreturn_type\n\u001b[1;32m    170\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages/patsy/highlevel.py:56\u001b[0m, in \u001b[0;36m_try_incr_builders\u001b[0;34m(formula_like, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(formula_like, ModelDesc):\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(eval_env, EvalEnvironment)\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdesign_matrix_builders\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mformula_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlhs_termlist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformula_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrhs_termlist\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_iter_maker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mNA_action\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages/patsy/build.py:746\u001b[0m, in \u001b[0;36mdesign_matrix_builders\u001b[0;34m(termlists, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[1;32m    743\u001b[0m factor_states \u001b[38;5;241m=\u001b[39m _factors_memorize(all_factors, data_iter_maker, eval_env)\n\u001b[1;32m    744\u001b[0m \u001b[38;5;66;03m# Now all the factors have working eval methods, so we can evaluate them\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;66;03m# on some data to find out what type of data they return.\u001b[39;00m\n\u001b[0;32m--> 746\u001b[0m (num_column_counts, cat_levels_contrasts) \u001b[38;5;241m=\u001b[39m \u001b[43m_examine_factor_types\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mall_factors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_iter_maker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNA_action\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;66;03m# Now we need the factor infos, which encapsulate the knowledge of\u001b[39;00m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;66;03m# how to turn any given factor into a chunk of data:\u001b[39;00m\n\u001b[1;32m    751\u001b[0m factor_infos \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages/patsy/build.py:491\u001b[0m, in \u001b[0;36m_examine_factor_types\u001b[0;34m(factors, factor_states, data_iter_maker, NA_action)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m data_iter_maker():\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m factor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(examine_needed):\n\u001b[0;32m--> 491\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[43mfactor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfactor_states\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfactor\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m factor \u001b[38;5;129;01min\u001b[39;00m cat_sniffers \u001b[38;5;129;01mor\u001b[39;00m guess_categorical(value):\n\u001b[1;32m    493\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m factor \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m cat_sniffers:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages/patsy/eval.py:599\u001b[0m, in \u001b[0;36mEvalFactor.eval\u001b[0;34m(self, memorize_state, data)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21meval\u001b[39m(\u001b[38;5;28mself\u001b[39m, memorize_state, data):\n\u001b[0;32m--> 599\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemorize_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_code\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemorize_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages/patsy/eval.py:582\u001b[0m, in \u001b[0;36mEvalFactor._eval\u001b[0;34m(self, code, memorize_state, data)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_eval\u001b[39m(\u001b[38;5;28mself\u001b[39m, code, memorize_state, data):\n\u001b[1;32m    581\u001b[0m     inner_namespace \u001b[38;5;241m=\u001b[39m VarLookupDict([data, memorize_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransforms\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[0;32m--> 582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_and_wrap_exc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mError evaluating factor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemorize_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_env\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minner_namespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_namespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/venv-thesis/lib/python3.12/site-packages/patsy/compat.py:43\u001b[0m, in \u001b[0;36mcall_and_wrap_exc\u001b[0;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     42\u001b[0m     new_exc \u001b[38;5;241m=\u001b[39m PatsyError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (msg, e\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, e), origin)\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mPatsyError\u001b[0m: Error evaluating factor: NameError: name 'FINANCIAL_DEBT' is not defined\n    FINANCIAL_DEBT ~ ROA + CASH_SEC_RATIO + PAYOUT_RATIO +     NEGATIVE_STOCKHOLDERS_EQUITY + NON_DEBT_TAX_SHIELDS +     ASSET_STRUCTURE + INTANGIBLE_ASSETS_RATIO + LOG_TOTAL_ASSETS +     PREVIOUS_DEBT_FINANCING + PREVIOUS_EXTERNAL_EQUITY_FINANCING\n    ^^^^^^^^^^^^^^"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# 🚀 Step 1: Define the regression variables\n",
    "regression_vars = [\n",
    "    'INTERNAL_FINANCE', 'ROA', 'CASH_SEC_RATIO', 'PAYOUT_RATIO',\n",
    "    'LEVERAGE', 'NEGATIVE_STOCKHOLDERS_EQUITY', 'NON_DEBT_TAX_SHIELDS',\n",
    "    'ASSET_STRUCTURE', 'INTANGIBLE_ASSETS_RATIO', 'LOG_TOTAL_ASSETS',\n",
    "    'PREVIOUS_DEBT_FINANCING', 'PREVIOUS_EXTERNAL_EQUITY_FINANCING'\n",
    "]\n",
    "\n",
    "# 🚀 Step 2: Create a new DataFrame with only the necessary variables\n",
    "df_regression = filtered_df[regression_vars].copy()\n",
    "\n",
    "# 🚀 Step 3: Remove missing values\n",
    "df_regression = df_regression.dropna()\n",
    "\n",
    "# 🚀 Step 4: Check for perfect separation and remove problematic variables\n",
    "perfect_predictors = df_regression.columns[df_regression.nunique() == 1].tolist()\n",
    "df_regression = df_regression.drop(columns=perfect_predictors, errors='ignore')\n",
    "\n",
    "# 🚀 Step 5: Check for multicollinearity (VIF test) and remove problematic variables\n",
    "X = df_regression.drop(columns=['INTERNAL_FINANCE'])\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "high_vif_vars = vif_data[vif_data[\"VIF\"] > 10][\"Variable\"].tolist()\n",
    "df_regression = df_regression.drop(columns=high_vif_vars, errors='ignore')\n",
    "\n",
    "# 🚀 Step 6: Standardize continuous variables\n",
    "continuous_vars = ['ROA', 'CASH_SEC_RATIO', 'PAYOUT_RATIO', 'LEVERAGE',\n",
    "                   'NON_DEBT_TAX_SHIELDS', 'ASSET_STRUCTURE', \n",
    "                   'INTANGIBLE_ASSETS_RATIO', 'LOG_TOTAL_ASSETS']\n",
    "scaler = StandardScaler()\n",
    "df_regression[continuous_vars] = scaler.fit_transform(df_regression[continuous_vars])\n",
    "\n",
    "# 🚀 Step 7: Run Logistic Regressions\n",
    "\n",
    "# Internal Finance Model\n",
    "formula_internal = \"\"\"\n",
    "    INTERNAL_FINANCE ~ ROA + CASH_SEC_RATIO + PAYOUT_RATIO +\n",
    "    NEGATIVE_STOCKHOLDERS_EQUITY + NON_DEBT_TAX_SHIELDS +\n",
    "    ASSET_STRUCTURE + INTANGIBLE_ASSETS_RATIO + LOG_TOTAL_ASSETS +\n",
    "    PREVIOUS_DEBT_FINANCING + PREVIOUS_EXTERNAL_EQUITY_FINANCING\n",
    "\"\"\"\n",
    "model_internal = smf.logit(formula=formula_internal, data=df_regression).fit()\n",
    "print(\"\\nInternal Financing Model:\")\n",
    "print(model_internal.summary())\n",
    "\n",
    "# Debt Financing Model\n",
    "formula_debt = \"\"\"\n",
    "    FINANCIAL_DEBT ~ ROA + CASH_SEC_RATIO + PAYOUT_RATIO +\n",
    "    NEGATIVE_STOCKHOLDERS_EQUITY + NON_DEBT_TAX_SHIELDS +\n",
    "    ASSET_STRUCTURE + INTANGIBLE_ASSETS_RATIO + LOG_TOTAL_ASSETS +\n",
    "    PREVIOUS_DEBT_FINANCING + PREVIOUS_EXTERNAL_EQUITY_FINANCING\n",
    "\"\"\"\n",
    "model_debt = smf.logit(formula=formula_debt, data=df_regression).fit()\n",
    "print(\"\\nDebt Financing Model:\")\n",
    "print(model_debt.summary())\n",
    "\n",
    "# External Equity Financing Model\n",
    "formula_equity = \"\"\"\n",
    "    EXTERNAL_EQUITY ~ ROA + CASH_SEC_RATIO + PAYOUT_RATIO +\n",
    "    NEGATIVE_STOCKHOLDERS_EQUITY + NON_DEBT_TAX_SHIELDS +\n",
    "    ASSET_STRUCTURE + INTANGIBLE_ASSETS_RATIO + LOG_TOTAL_ASSETS +\n",
    "    PREVIOUS_DEBT_FINANCING + PREVIOUS_EXTERNAL_EQUITY_FINANCING\n",
    "\"\"\"\n",
    "model_equity = smf.logit(formula=formula_equity, data=df_regression).fit()\n",
    "print(\"\\nEquity Financing Model:\")\n",
    "print(model_equity.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the subset with HGFs + Descriptive Statistics.\n",
    "*up until this point, all companies have been in the same DF.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485744\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame with high-growth companies\n",
    "high_growth_orgnr = filtered_df[filtered_df['HIGH_GROWTH'] == 1]['ORGNR'].unique()\n",
    "high_growth_df = filtered_df[filtered_df['ORGNR'].isin(high_growth_orgnr)]\n",
    "\n",
    "# Create DataFrame with non-high-growth companies\n",
    "non_high_growth_df = filtered_df[~filtered_df['ORGNR'].isin(high_growth_orgnr)]\n",
    "\n",
    "# Create a DataFrame with unique high-growth companies\n",
    "unique_high_growth_df = high_growth_df.drop_duplicates(subset='ORGNR')\n",
    "\n",
    "# Create a DataFrame with unique non-high-growth companies\n",
    "unique_non_high_growth_df = non_high_growth_df.drop_duplicates(subset='ORGNR')\n",
    "print(len(unique_non_high_growth_df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "488611"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the unique high-growth companies with the non-high-growth companies\n",
    "combined_df = pd.concat([unique_high_growth_df, unique_non_high_growth_df])\n",
    "\n",
    "print(len(combined_df))\n",
    "combined_df['ORGNR'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDUSTRY\n",
      "Corporate services        30.203782\n",
      "Shopping goods            21.698857\n",
      "Construction industry     14.701675\n",
      "Health & Education         6.917978\n",
      "IT & Electronics           6.683845\n",
      "Finance & Real estate      6.570462\n",
      "Industrial goods           5.921070\n",
      "Convenience goods          3.622309\n",
      "Telecom & Media            1.947152\n",
      "Materials                  1.244753\n",
      "Energy & Environment       0.488118\n",
      "Total                    100.000000\n",
      "Name: proportion, dtype: float64\n",
      "INDUSTRY\n",
      "Corporate services        25.776073\n",
      "Construction industry     19.532612\n",
      "Shopping goods            14.893617\n",
      "Health & Education        12.452040\n",
      "Industrial goods           9.208232\n",
      "IT & Electronics           8.161842\n",
      "Convenience goods          3.348448\n",
      "Finance & Real estate      3.034531\n",
      "Telecom & Media            1.639344\n",
      "Materials                  1.185909\n",
      "Energy & Environment       0.767353\n",
      "Total                    100.000000\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of each industry among all companies\n",
    "industry_percentage = combined_df['INDUSTRY'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Calculate the total percentage to check for rounding errors\n",
    "total_percentage = industry_percentage.sum()\n",
    "\n",
    "# If the total percentage is not exactly 100, adjust the last value\n",
    "if total_percentage != 100:\n",
    "    difference = 100 - total_percentage\n",
    "    industry_percentage.iloc[-1] += difference\n",
    "\n",
    "# Add a row for the total percentage\n",
    "industry_percentage['Total'] = industry_percentage.sum()\n",
    "\n",
    "# Display the result\n",
    "print(industry_percentage)\n",
    "\n",
    "# Calculate the percentage of each industry among high-growth companies\n",
    "industry_percentage = unique_high_growth_df['INDUSTRY'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Calculate the total percentage to check for rounding errors\n",
    "total_percentage = industry_percentage.sum()\n",
    "\n",
    "# If the total percentage is not exactly 100, adjust the last value\n",
    "if total_percentage != 100:\n",
    "    difference = 100 - total_percentage\n",
    "    industry_percentage.iloc[-1] += difference\n",
    "\n",
    "# Add a row for the total percentage\n",
    "industry_percentage['Total'] = industry_percentage.sum()\n",
    "\n",
    "# Display the result\n",
    "print(industry_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDUSTRY\n",
      "Energy & Environment     775.081444\n",
      "Materials                719.238926\n",
      "Industrial goods         504.911862\n",
      "Telecom & Media          473.896490\n",
      "Convenience goods        350.011102\n",
      "Health & Education       154.906440\n",
      "IT & Electronics         153.526295\n",
      "Shopping goods           109.110065\n",
      "Finance & Real estate     71.700881\n",
      "Corporate services        53.337668\n",
      "Construction industry     25.057200\n",
      "Name: br01c_goodwill, dtype: float64\n",
      "INDUSTRY\n",
      "Energy & Environment     1574.681818\n",
      "Industrial goods         1268.776515\n",
      "IT & Electronics          729.713675\n",
      "Shopping goods            591.971897\n",
      "Finance & Real estate     561.574713\n",
      "Telecom & Media           477.297872\n",
      "Health & Education        339.000000\n",
      "Corporate services        178.174560\n",
      "Convenience goods         134.520833\n",
      "Construction industry      90.646429\n",
      "Materials                  25.617647\n",
      "Name: br01c_goodwill, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average goodwill for each industry among all companies\n",
    "avg_goodwill_by_industry_all = combined_df.groupby('INDUSTRY')['br01c_goodwill'].mean()\n",
    "\n",
    "# Sort by average goodwill in descending order\n",
    "average_goodwill_by_industry = avg_goodwill_by_industry_all.sort_values(ascending=False)\n",
    "\n",
    "# Display the result\n",
    "print(average_goodwill_by_industry)\n",
    "\n",
    "# Calculate the average goodwill for each industry among HGFs\n",
    "avg_goodwill_by_industry_high_growth = unique_high_growth_df.groupby('INDUSTRY')['br01c_goodwill'].mean()\n",
    "\n",
    "# Sort by average goodwill in descending order\n",
    "avg_goodwill_by_industry_high_growth = avg_goodwill_by_industry_high_growth.sort_values(ascending=False)\n",
    "\n",
    "# Display the result\n",
    "print(avg_goodwill_by_industry_high_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDUSTRY\n",
      "Energy & Environment     775.081444\n",
      "Materials                719.238926\n",
      "Industrial goods         504.911862\n",
      "Telecom & Media          473.896490\n",
      "Convenience goods        350.011102\n",
      "Health & Education       154.906440\n",
      "IT & Electronics         153.526295\n",
      "Shopping goods           109.110065\n",
      "Finance & Real estate     71.700881\n",
      "Corporate services        53.337668\n",
      "Construction industry     25.057200\n",
      "Name: br01c_goodwill, dtype: float64\n",
      "INDUSTRY\n",
      "Energy & Environment     612610.318182\n",
      "Materials                209139.882353\n",
      "Finance & Real estate     87681.678161\n",
      "Industrial goods          71223.469697\n",
      "Convenience goods         47523.437500\n",
      "Shopping goods            41027.800937\n",
      "IT & Electronics          31189.606838\n",
      "Construction industry     30803.689286\n",
      "Corporate services        25940.364005\n",
      "Telecom & Media           25127.085106\n",
      "Health & Education        21918.308123\n",
      "Name: rr01_ntoms, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average goodwill for each industry among all companies\n",
    "avg_sales_by_industry_all = combined_df.groupby('INDUSTRY')['rr01_ntoms'].mean()\n",
    "\n",
    "# Sort by average goodwill in descending order\n",
    "average_sales_by_industry = avg_goodwill_by_industry_all.sort_values(ascending=False)\n",
    "\n",
    "# Display the result\n",
    "print(average_sales_by_industry)\n",
    "\n",
    "# Calculate the average goodwill for each industry among HGFs\n",
    "avg_sales_by_industry_high_growth = unique_high_growth_df.groupby('INDUSTRY')['rr01_ntoms'].mean()\n",
    "\n",
    "# Sort by average goodwill in descending order\n",
    "avg_sales_by_industry_high_growth = avg_sales_by_industry_high_growth.sort_values(ascending=False)\n",
    "\n",
    "# Display the result\n",
    "print(avg_sales_by_industry_high_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average size category by industry (all companies):\n",
      "INDUSTRY\n",
      "Industrial goods         1.612215\n",
      "Materials                1.396251\n",
      "Convenience goods        1.334991\n",
      "Energy & Environment     1.208386\n",
      "Construction industry    1.163126\n",
      "Shopping goods           1.139479\n",
      "Health & Education       1.092391\n",
      "Corporate services       1.017381\n",
      "IT & Electronics         1.010135\n",
      "Telecom & Media          0.994639\n",
      "Finance & Real estate    0.644655\n",
      "Name: ser_stklf, dtype: float64\n",
      "\n",
      "Average size category by industry (high-growth firms):\n",
      "INDUSTRY\n",
      "Materials                3.941176\n",
      "Energy & Environment     3.909091\n",
      "Industrial goods         3.625000\n",
      "Telecom & Media          3.617021\n",
      "Health & Education       3.610644\n",
      "Finance & Real estate    3.505747\n",
      "Shopping goods           3.494145\n",
      "Corporate services       3.488498\n",
      "IT & Electronics         3.470085\n",
      "Convenience goods        3.416667\n",
      "Construction industry    3.385714\n",
      "Name: ser_stklf, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'combined_df' is your DataFrame and 'ser_stklf' is the column for size category\n",
    "\n",
    "# Calculate the average size category for each industry among all companies\n",
    "avg_size_by_industry_all = combined_df.groupby('INDUSTRY')['ser_stklf'].mean()\n",
    "\n",
    "# Sort by average size category in descending order\n",
    "avg_size_by_industry_all = avg_size_by_industry_all.sort_values(ascending=False)\n",
    "\n",
    "# Display the result\n",
    "print(\"Average size category by industry (all companies):\")\n",
    "print(avg_size_by_industry_all)\n",
    "\n",
    "# Calculate the average size category for each industry among HGFs\n",
    "avg_size_by_industry_high_growth = unique_high_growth_df.groupby('INDUSTRY')['ser_stklf'].mean()\n",
    "\n",
    "# Sort by average size category in descending order\n",
    "avg_size_by_industry_high_growth = avg_size_by_industry_high_growth.sort_values(ascending=False)\n",
    "\n",
    "# Display the result\n",
    "print(\"\\nAverage size category by industry (high-growth firms):\")\n",
    "print(avg_size_by_industry_high_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data saved to ./serrano/serrano_2024_Stata/firms.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Save the filtered DataFrame to an Excel file\n",
    "output_path = \"./serrano/serrano_2024_Stata/firms.xlsx\"\n",
    "filtered_df.head(20000).to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"Filtered data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Internal finance %  Financial debt %  External equity %\n",
      "ser_year                                                         \n",
      "2007.0                   0.0               0.0                0.0\n",
      "2008.0                   0.0               0.0                0.0\n",
      "2009.0                   0.0               0.0                0.0\n",
      "2010.0                   0.0               0.0                0.0\n",
      "2011.0                   0.0               0.0                0.0\n",
      "2012.0                   0.0               0.0                0.0\n",
      "2013.0                   0.0               0.0                0.0\n",
      "2014.0                   0.0               0.0                0.0\n",
      "2015.0                   0.0               0.0                0.0\n",
      "2016.0                   0.0               0.0                0.0\n",
      "2017.0                   0.0               0.0                0.0\n",
      "2018.0                   0.0               0.0                0.0\n",
      "2019.0                   0.0               0.0                0.0\n",
      "2020.0                   0.0               0.0                0.0\n",
      "2021.0                   0.0               0.0                0.0\n",
      "2022.0                   0.0               0.0                0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/d0m27jy17d36rd2w_8y762cr0000gn/T/ipykernel_72693/6120956.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  summary_table = combined_df.groupby('ser_year').apply(lambda x: pd.Series({\n"
     ]
    }
   ],
   "source": [
    "# Group by 'ser_year' and calculate the percentage of firms with 1 in each column\n",
    "summary_table = combined_df.groupby('ser_year').apply(lambda x: pd.Series({\n",
    "    'Internal finance %': (x['INTERNAL_FINANCE'].sum() / len(x)) * 100,\n",
    "    'Financial debt %': (x['FINANCIAL_DEBT'].sum() / len(x)) * 100,\n",
    "    'External equity %': (x['EXTERNAL_EQUITY'].sum() / len(x)) * 100\n",
    "}))\n",
    "\n",
    "# Display the summary table\n",
    "print(summary_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
