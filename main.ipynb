{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_stata(\"./serrano/serrano_2024_Stata/serrano.dta\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['ORGNR', 'KOMORGNR', 'KOMNAMN', 'BSTYP', 'STATUS', 'REDTYP', 'BELKOD', 'UTDBEL', 'NTOMS', 'LAGERF', 'AKTARB', 'ROINTOV1', 'RAVAR', 'HANDVAR', 'EXTKOSOV', 'PERSKOS', 'AVSKRIV', 'JFRST1', 'RORKOOV1', 'RORRESUL', 'RESAND', 'RTEINKNC', 'RTEINEXT', 'RTEINOV', 'RTEKOKNC', 'RTEKOEXT', 'RTEKOOV', 'JFRSTFIN', 'RESEFIN', 'EXTRAINT', 'EXTRAKOS', 'KNCBDR', 'AGTSK', 'BSLDISP', 'SKATTER', 'MININTRR', 'RESAR', 'KOSALVAR', 'BRUTORES', 'FORSKO', 'ADMKO', 'FOUKO', 'JFRST2', 'ROINTOV2', 'RORKOOV2', 'EJINBET', 'FOUBAUTG', 'PATLIC', 'GOODWILL', 'IMANLOV', 'IMANLSU', 'BYGGMARK', 'MASK', 'INVENT', 'MASKINV', 'MATANLOV', 'MATANLSU', 'ANDKNC', 'LFORDKNC', 'LANDELAG', 'FIANLTOV', 'FIANLTSU', 'ANLTSU', 'PAGARB', 'LAGEROV', 'LAGERSU', 'KUNDFORD', 'KFORDKNC', 'KFORDOV', 'KFORDSU', 'KPLACSU', 'KABASU', 'OMSTGSU', 'TILLGSU', 'AKTIEKAP', 'OVERKURS', 'UPPSKR', 'OVRGBKAP', 'BALRES', 'KNCBDREL', 'AGTSKEL', 'RESARB', 'EKSU', 'OBESKRES', 'MININTR', 'AVSSU', 'LSKKRIN', 'LSKKNC', 'LSKOV', 'LSKSU', 'KSKKRIN', 'KSKLEV', 'KSKKNC', 'KSKOV', 'KSKSU', 'EKSKSU', 'RTENTO', 'ANTANST', 'LONLEDN', 'LONOV', 'SOCKOSTN', 'TANTLEDN', 'RESLONOV', 'AVGVED', 'AVSKSALV', 'AVSKFSG', 'AVSKADM', 'AVSKFOU', 'AVSKOV2', 'AVSKOSPC', 'INTFTG', 'INTFAST', 'SAKOV', 'SAKKOM', 'SAKSU', 'AGTSKV', 'ANSVFOV', 'ANSVFKOM', 'ANSVFSU', 'CHKRBEV', 'CHKRUTN', 'REVBER', 'BOLSTPRO', 'MODDTM', 'BSLSTART', 'BSLSLUT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/d0m27jy17d36rd2w_8y762cr0000gn/T/ipykernel_72693/1801518813.py:10: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  filtered_df['TURNOVER_GROWTH'] = filtered_df.groupby('ORGNR')['rr01_ntoms'].pct_change()\n",
      "/var/folders/pd/d0m27jy17d36rd2w_8y762cr0000gn/T/ipykernel_72693/1801518813.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  filtered_df['TURNOVER_GROWTH'] = filtered_df.groupby('ORGNR')['rr01_ntoms'].pct_change()\n",
      "/var/folders/pd/d0m27jy17d36rd2w_8y762cr0000gn/T/ipykernel_72693/1801518813.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['TURNOVER_GROWTH'] = filtered_df.groupby('ORGNR')['rr01_ntoms'].pct_change()\n",
      "/var/folders/pd/d0m27jy17d36rd2w_8y762cr0000gn/T/ipykernel_72693/1801518813.py:13: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  filtered_df['HIGH_GROWTH'] = filtered_df.groupby('ORGNR').apply(\n",
      "/var/folders/pd/d0m27jy17d36rd2w_8y762cr0000gn/T/ipykernel_72693/1801518813.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  filtered_df['HIGH_GROWTH'] = filtered_df.groupby('ORGNR').apply(\n",
      "/var/folders/pd/d0m27jy17d36rd2w_8y762cr0000gn/T/ipykernel_72693/1801518813.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['HIGH_GROWTH'] = filtered_df.groupby('ORGNR').apply(\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame\n",
    "filtered_df = df[(df['ser_year'] >= 2007) & # remove data before 2007\n",
    "                 (df['ser_jurform'] == 49) & # aktiebolag\n",
    "                 (df['ser_aktiv'] == 1) & # active companies\n",
    "                 (df['ser_ftgkategori'] == 30)] # private companies, i.e., not state-owned etc.\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the annual growth rate for each company and add it as a new column\n",
    "filtered_df['TURNOVER_GROWTH'] = filtered_df.groupby('ORGNR')['rr01_ntoms'].pct_change()\n",
    "\n",
    "# Identify high-growth periods and create a new binary column\n",
    "filtered_df['HIGH_GROWTH'] = filtered_df.groupby('ORGNR').apply(\n",
    "    lambda x: ((x['TURNOVER_GROWTH'] > 0.20).rolling(window=3).sum() == 3) & \n",
    "              (x['ser_stklf'].iloc[0] in [3, 4, 5, 6, 7]) # only consider companies with at least 10 employees, based on size category\n",
    ").reset_index(level=0, drop=True).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'ORGNR' and count the number of rows where 'ser_stklf' is 0\n",
    "zero_employee_counts = filtered_df[filtered_df['ser_stklf'] == 0].groupby('ORGNR').size()\n",
    "\n",
    "# Identify companies with more than 4 rows where 'ser_stklf' is 0\n",
    "companies_to_remove = zero_employee_counts[zero_employee_counts > 4].index\n",
    "\n",
    "# Filter out rows associated with these companies\n",
    "filtered_df = filtered_df[~filtered_df['ORGNR'].isin(companies_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529430"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['ORGNR'].nunique() # amount of companies in this filtered dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add one industry to all companies.\n",
    "dict_of_industries = {\n",
    "    10: 'Energy & Environment',\n",
    "    15: 'Materials',\n",
    "    20: 'Industrial goods',\n",
    "    22: 'Construction industry',\n",
    "    25: 'Shopping goods',\n",
    "    30: 'Convenience goods',\n",
    "    35: 'Health & Education',\n",
    "    40: 'Finance & Real estate',\n",
    "    45: 'IT & Electronics',\n",
    "    50: 'Telecom & Media',\n",
    "    60: 'Corporate services',\n",
    "    98: 'Other',\n",
    "    99: 'SNI07 missing'\n",
    "}\n",
    "\n",
    "# Determine the most frequent 'bransch_borsbransch_konv' value for each company\n",
    "most_frequent_industry = filtered_df.groupby('ORGNR')['bransch_borsbransch_konv'].agg(lambda x: x.mode()[0])\n",
    "\n",
    "# Map the most frequent 'bransch_borsbransch_konv' value to the corresponding industry name\n",
    "most_frequent_industry = most_frequent_industry.map(dict_of_industries)\n",
    "\n",
    "# Add the new 'INDUSTRY' column to the DataFrame\n",
    "filtered_df = filtered_df.merge(most_frequent_industry.rename('INDUSTRY'), on='ORGNR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where the 'INDUSTRY' column is 'SNI07 missing' or 'Other'\n",
    "filtered_df = filtered_df[~filtered_df['INDUSTRY'].isin(['SNI07 missing', 'Other'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3742401\n",
      "488611\n"
     ]
    }
   ],
   "source": [
    "print(len(filtered_df))\n",
    "print(len(filtered_df['ORGNR'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add varibles from Vanacker & Manigart (2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/d0m27jy17d36rd2w_8y762cr0000gn/T/ipykernel_72693/2737011162.py:4: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  filtered_df['br10e_balres_pct_change'] = filtered_df.groupby('ORGNR')['br10e_balres'].pct_change()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data with internal finance saved to ./serrano/serrano_2024_Stata/filtered_firms_with_internal_finance.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Internal Finance\n",
    "# N.D., this is only retained earnings, not profit/loss of the current year, maybe that should be included too.\n",
    "# Maybe not since that profit might be used for dividends so then maybe we list it as a internal finance thing but in reailty that money is not used for investments.\n",
    "\n",
    "# Calculate the percentage change in retained earnings from the previous year\n",
    "filtered_df['br10e_balres_pct_change'] = filtered_df.groupby('ORGNR')['br10e_balres'].pct_change()\n",
    "\n",
    "# Calculate the percentage increase in retained earnings relative to total assets\n",
    "filtered_df['INTERNAL_FINANCE'] = (filtered_df['br10e_balres_pct_change'] * filtered_df.groupby('ORGNR')['br10e_balres'].shift(1) / filtered_df['br09_tillgsu']) > 0.05\n",
    "\n",
    "# Convert the boolean values to binary (1 or 0)\n",
    "filtered_df['INTERNAL_FINANCE'] = filtered_df['INTERNAL_FINANCE'].astype(int)\n",
    "\n",
    "# Drop the temporary column\n",
    "filtered_df = filtered_df.drop(columns=['br10e_balres_pct_change'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/d0m27jy17d36rd2w_8y762cr0000gn/T/ipykernel_72693/499950134.py:7: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  filtered_df['combined_financial_debt_pct_change'] = filtered_df.groupby('ORGNR')['combined_financial_debt'].pct_change()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data with internal finance and financial debt saved to ./serrano/serrano_2024_Stata/filtered_firms_with_internal_finance_and_financial_debt.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Financial Debt\n",
    "\n",
    "# Calculate the combined financial debt\n",
    "filtered_df['combined_financial_debt'] = filtered_df['br14_kskkrin'] + filtered_df['br16_lskkrin']\n",
    "\n",
    "# Calculate the percentage change in combined financial debt from the previous year\n",
    "filtered_df['combined_financial_debt_pct_change'] = filtered_df.groupby('ORGNR')['combined_financial_debt'].pct_change()\n",
    "\n",
    "# Calculate the percentage increase in combined financial debt relative to total assets\n",
    "filtered_df['FINANCIAL_DEBT'] = (filtered_df['combined_financial_debt_pct_change'] * filtered_df.groupby('ORGNR')['combined_financial_debt'].shift(1) / filtered_df['br09_tillgsu']) > 0.05\n",
    "\n",
    "# Convert the boolean values to binary (1 or 0)\n",
    "filtered_df['FINANCIAL_DEBT'] = filtered_df['FINANCIAL_DEBT'].astype(int)\n",
    "\n",
    "# Drop the temporary columns\n",
    "filtered_df = filtered_df.drop(columns=['combined_financial_debt', 'combined_financial_debt_pct_change'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/d0m27jy17d36rd2w_8y762cr0000gn/T/ipykernel_72693/3300434013.py:7: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  filtered_df['external_equity_pct_change'] = filtered_df.groupby('ORGNR')['external_equity'].pct_change()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data with internal finance, financial debt, and external equity saved to ./serrano/serrano_2024_Stata/filtered_firms_with_internal_finance_financial_debt_and_external_equity.xlsx\n"
     ]
    }
   ],
   "source": [
    "# External Equity\n",
    "\n",
    "# Calculate the combined external equity\n",
    "filtered_df['external_equity'] = filtered_df['br10a_aktiekap'] + filtered_df['br10b_overkurs']\n",
    "\n",
    "# Calculate the percentage change in external equity from the previous year\n",
    "filtered_df['external_equity_pct_change'] = filtered_df.groupby('ORGNR')['external_equity'].pct_change()\n",
    "\n",
    "# Calculate the percentage increase in external equity relative to total assets\n",
    "filtered_df['EXTERNAL_EQUITY'] = (filtered_df['external_equity_pct_change'] * filtered_df.groupby('ORGNR')['external_equity'].shift(1) / filtered_df['br09_tillgsu']) > 0.05\n",
    "\n",
    "# Convert the boolean values to binary (1 or 0)\n",
    "filtered_df['EXTERNAL_EQUITY'] = filtered_df['EXTERNAL_EQUITY'].astype(int)\n",
    "\n",
    "# Drop the temporary columns\n",
    "filtered_df = filtered_df.drop(columns=['external_equity', 'external_equity_pct_change'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Internal finance %  Financial debt %  External equity %\n",
      "ser_year                                                         \n",
      "2007.0              0.000000          0.000000           0.000000\n",
      "2008.0             23.747299          8.270698           0.546476\n",
      "2009.0             21.048502          7.009052           0.561924\n",
      "2010.0             20.527704          6.678210           0.480981\n",
      "2011.0             22.425112          6.636156           0.207089\n",
      "2012.0             21.910987          6.253410           0.183005\n",
      "2013.0             20.447692          5.660736           0.169523\n",
      "2014.0             23.330864          5.391598           0.171357\n",
      "2015.0             24.501878          5.199335           0.180466\n",
      "2016.0             24.259159          5.284724           0.163076\n",
      "2017.0             23.330448          5.287637           0.121587\n",
      "2018.0             26.690854          5.170140           0.117169\n",
      "2019.0             27.124858          4.762405           0.097000\n",
      "2020.0             30.448417          4.004186           0.095036\n",
      "2021.0             29.263200          3.788856           0.098343\n",
      "2022.0             26.759036          3.778614           0.083434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/d0m27jy17d36rd2w_8y762cr0000gn/T/ipykernel_72693/3889269946.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  summary_table = filtered_df.groupby('ser_year').apply(lambda x: pd.Series({\n"
     ]
    }
   ],
   "source": [
    "# Group by 'ser_year' and calculate the percentage of firms with 1 in each column\n",
    "summary_table = filtered_df.groupby('ser_year').apply(lambda x: pd.Series({\n",
    "    'Internal finance %': (x['INTERNAL_FINANCE'].sum() / len(x)) * 100,\n",
    "    'Financial debt %': (x['FINANCIAL_DEBT'].sum() / len(x)) * 100,\n",
    "    'External equity %': (x['EXTERNAL_EQUITY'].sum() / len(x)) * 100\n",
    "}))\n",
    "\n",
    "# Display the summary table\n",
    "print(summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485744\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame with high-growth companies\n",
    "high_growth_orgnr = filtered_df[filtered_df['HIGH_GROWTH'] == 1]['ORGNR'].unique()\n",
    "high_growth_df = filtered_df[filtered_df['ORGNR'].isin(high_growth_orgnr)]\n",
    "\n",
    "# Create DataFrame with non-high-growth companies\n",
    "non_high_growth_df = filtered_df[~filtered_df['ORGNR'].isin(high_growth_orgnr)]\n",
    "\n",
    "# Create a DataFrame with unique high-growth companies\n",
    "unique_high_growth_df = high_growth_df.drop_duplicates(subset='ORGNR')\n",
    "\n",
    "# Create a DataFrame with unique non-high-growth companies\n",
    "unique_non_high_growth_df = non_high_growth_df.drop_duplicates(subset='ORGNR')\n",
    "print(len(unique_non_high_growth_df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "488611"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the unique high-growth companies with the non-high-growth companies\n",
    "combined_df = pd.concat([unique_high_growth_df, unique_non_high_growth_df])\n",
    "\n",
    "print(len(combined_df))\n",
    "combined_df['ORGNR'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDUSTRY\n",
      "Corporate services        30.203782\n",
      "Shopping goods            21.698857\n",
      "Construction industry     14.701675\n",
      "Health & Education         6.917978\n",
      "IT & Electronics           6.683845\n",
      "Finance & Real estate      6.570462\n",
      "Industrial goods           5.921070\n",
      "Convenience goods          3.622309\n",
      "Telecom & Media            1.947152\n",
      "Materials                  1.244753\n",
      "Energy & Environment       0.488118\n",
      "Total                    100.000000\n",
      "Name: proportion, dtype: float64\n",
      "INDUSTRY\n",
      "Corporate services        25.776073\n",
      "Construction industry     19.532612\n",
      "Shopping goods            14.893617\n",
      "Health & Education        12.452040\n",
      "Industrial goods           9.208232\n",
      "IT & Electronics           8.161842\n",
      "Convenience goods          3.348448\n",
      "Finance & Real estate      3.034531\n",
      "Telecom & Media            1.639344\n",
      "Materials                  1.185909\n",
      "Energy & Environment       0.767353\n",
      "Total                    100.000000\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of each industry among all companies\n",
    "industry_percentage = combined_df['INDUSTRY'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Calculate the total percentage to check for rounding errors\n",
    "total_percentage = industry_percentage.sum()\n",
    "\n",
    "# If the total percentage is not exactly 100, adjust the last value\n",
    "if total_percentage != 100:\n",
    "    difference = 100 - total_percentage\n",
    "    industry_percentage.iloc[-1] += difference\n",
    "\n",
    "# Add a row for the total percentage\n",
    "industry_percentage['Total'] = industry_percentage.sum()\n",
    "\n",
    "# Display the result\n",
    "print(industry_percentage)\n",
    "\n",
    "# Calculate the percentage of each industry among high-growth companies\n",
    "industry_percentage = unique_high_growth_df['INDUSTRY'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Calculate the total percentage to check for rounding errors\n",
    "total_percentage = industry_percentage.sum()\n",
    "\n",
    "# If the total percentage is not exactly 100, adjust the last value\n",
    "if total_percentage != 100:\n",
    "    difference = 100 - total_percentage\n",
    "    industry_percentage.iloc[-1] += difference\n",
    "\n",
    "# Add a row for the total percentage\n",
    "industry_percentage['Total'] = industry_percentage.sum()\n",
    "\n",
    "# Display the result\n",
    "print(industry_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDUSTRY\n",
      "Energy & Environment     775.081444\n",
      "Materials                719.238926\n",
      "Industrial goods         504.911862\n",
      "Telecom & Media          473.896490\n",
      "Convenience goods        350.011102\n",
      "Health & Education       154.906440\n",
      "IT & Electronics         153.526295\n",
      "Shopping goods           109.110065\n",
      "Finance & Real estate     71.700881\n",
      "Corporate services        53.337668\n",
      "Construction industry     25.057200\n",
      "Name: br01c_goodwill, dtype: float64\n",
      "INDUSTRY\n",
      "Energy & Environment     1574.681818\n",
      "Industrial goods         1268.776515\n",
      "IT & Electronics          729.713675\n",
      "Shopping goods            591.971897\n",
      "Finance & Real estate     561.574713\n",
      "Telecom & Media           477.297872\n",
      "Health & Education        339.000000\n",
      "Corporate services        178.174560\n",
      "Convenience goods         134.520833\n",
      "Construction industry      90.646429\n",
      "Materials                  25.617647\n",
      "Name: br01c_goodwill, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average goodwill for each industry among all companies\n",
    "avg_goodwill_by_industry_all = combined_df.groupby('INDUSTRY')['br01c_goodwill'].mean()\n",
    "\n",
    "# Sort by average goodwill in descending order\n",
    "average_goodwill_by_industry = avg_goodwill_by_industry_all.sort_values(ascending=False)\n",
    "\n",
    "# Display the result\n",
    "print(average_goodwill_by_industry)\n",
    "\n",
    "# Calculate the average goodwill for each industry among HGFs\n",
    "avg_goodwill_by_industry_high_growth = unique_high_growth_df.groupby('INDUSTRY')['br01c_goodwill'].mean()\n",
    "\n",
    "# Sort by average goodwill in descending order\n",
    "avg_goodwill_by_industry_high_growth = avg_goodwill_by_industry_high_growth.sort_values(ascending=False)\n",
    "\n",
    "# Display the result\n",
    "print(avg_goodwill_by_industry_high_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDUSTRY\n",
      "Energy & Environment     775.081444\n",
      "Materials                719.238926\n",
      "Industrial goods         504.911862\n",
      "Telecom & Media          473.896490\n",
      "Convenience goods        350.011102\n",
      "Health & Education       154.906440\n",
      "IT & Electronics         153.526295\n",
      "Shopping goods           109.110065\n",
      "Finance & Real estate     71.700881\n",
      "Corporate services        53.337668\n",
      "Construction industry     25.057200\n",
      "Name: br01c_goodwill, dtype: float64\n",
      "INDUSTRY\n",
      "Energy & Environment     612610.318182\n",
      "Materials                209139.882353\n",
      "Finance & Real estate     87681.678161\n",
      "Industrial goods          71223.469697\n",
      "Convenience goods         47523.437500\n",
      "Shopping goods            41027.800937\n",
      "IT & Electronics          31189.606838\n",
      "Construction industry     30803.689286\n",
      "Corporate services        25940.364005\n",
      "Telecom & Media           25127.085106\n",
      "Health & Education        21918.308123\n",
      "Name: rr01_ntoms, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average goodwill for each industry among all companies\n",
    "avg_sales_by_industry_all = combined_df.groupby('INDUSTRY')['rr01_ntoms'].mean()\n",
    "\n",
    "# Sort by average goodwill in descending order\n",
    "average_sales_by_industry = avg_goodwill_by_industry_all.sort_values(ascending=False)\n",
    "\n",
    "# Display the result\n",
    "print(average_sales_by_industry)\n",
    "\n",
    "# Calculate the average goodwill for each industry among HGFs\n",
    "avg_sales_by_industry_high_growth = unique_high_growth_df.groupby('INDUSTRY')['rr01_ntoms'].mean()\n",
    "\n",
    "# Sort by average goodwill in descending order\n",
    "avg_sales_by_industry_high_growth = avg_sales_by_industry_high_growth.sort_values(ascending=False)\n",
    "\n",
    "# Display the result\n",
    "print(avg_sales_by_industry_high_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average size category by industry (all companies):\n",
      "INDUSTRY\n",
      "Industrial goods         1.612215\n",
      "Materials                1.396251\n",
      "Convenience goods        1.334991\n",
      "Energy & Environment     1.208386\n",
      "Construction industry    1.163126\n",
      "Shopping goods           1.139479\n",
      "Health & Education       1.092391\n",
      "Corporate services       1.017381\n",
      "IT & Electronics         1.010135\n",
      "Telecom & Media          0.994639\n",
      "Finance & Real estate    0.644655\n",
      "Name: ser_stklf, dtype: float64\n",
      "\n",
      "Average size category by industry (high-growth firms):\n",
      "INDUSTRY\n",
      "Materials                3.941176\n",
      "Energy & Environment     3.909091\n",
      "Industrial goods         3.625000\n",
      "Telecom & Media          3.617021\n",
      "Health & Education       3.610644\n",
      "Finance & Real estate    3.505747\n",
      "Shopping goods           3.494145\n",
      "Corporate services       3.488498\n",
      "IT & Electronics         3.470085\n",
      "Convenience goods        3.416667\n",
      "Construction industry    3.385714\n",
      "Name: ser_stklf, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'combined_df' is your DataFrame and 'ser_stklf' is the column for size category\n",
    "\n",
    "# Calculate the average size category for each industry among all companies\n",
    "avg_size_by_industry_all = combined_df.groupby('INDUSTRY')['ser_stklf'].mean()\n",
    "\n",
    "# Sort by average size category in descending order\n",
    "avg_size_by_industry_all = avg_size_by_industry_all.sort_values(ascending=False)\n",
    "\n",
    "# Display the result\n",
    "print(\"Average size category by industry (all companies):\")\n",
    "print(avg_size_by_industry_all)\n",
    "\n",
    "# Calculate the average size category for each industry among HGFs\n",
    "avg_size_by_industry_high_growth = unique_high_growth_df.groupby('INDUSTRY')['ser_stklf'].mean()\n",
    "\n",
    "# Sort by average size category in descending order\n",
    "avg_size_by_industry_high_growth = avg_size_by_industry_high_growth.sort_values(ascending=False)\n",
    "\n",
    "# Display the result\n",
    "print(\"\\nAverage size category by industry (high-growth firms):\")\n",
    "print(avg_size_by_industry_high_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data saved to ./serrano/serrano_2024_Stata/firms.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Save the filtered DataFrame to an Excel file\n",
    "output_path = \"./serrano/serrano_2024_Stata/firms.xlsx\"\n",
    "filtered_df.head(20000).to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"Filtered data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Internal finance %  Financial debt %  External equity %\n",
      "ser_year                                                         \n",
      "2007.0                   0.0               0.0                0.0\n",
      "2008.0                   0.0               0.0                0.0\n",
      "2009.0                   0.0               0.0                0.0\n",
      "2010.0                   0.0               0.0                0.0\n",
      "2011.0                   0.0               0.0                0.0\n",
      "2012.0                   0.0               0.0                0.0\n",
      "2013.0                   0.0               0.0                0.0\n",
      "2014.0                   0.0               0.0                0.0\n",
      "2015.0                   0.0               0.0                0.0\n",
      "2016.0                   0.0               0.0                0.0\n",
      "2017.0                   0.0               0.0                0.0\n",
      "2018.0                   0.0               0.0                0.0\n",
      "2019.0                   0.0               0.0                0.0\n",
      "2020.0                   0.0               0.0                0.0\n",
      "2021.0                   0.0               0.0                0.0\n",
      "2022.0                   0.0               0.0                0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/d0m27jy17d36rd2w_8y762cr0000gn/T/ipykernel_72693/6120956.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  summary_table = combined_df.groupby('ser_year').apply(lambda x: pd.Series({\n"
     ]
    }
   ],
   "source": [
    "# Group by 'ser_year' and calculate the percentage of firms with 1 in each column\n",
    "summary_table = combined_df.groupby('ser_year').apply(lambda x: pd.Series({\n",
    "    'Internal finance %': (x['INTERNAL_FINANCE'].sum() / len(x)) * 100,\n",
    "    'Financial debt %': (x['FINANCIAL_DEBT'].sum() / len(x)) * 100,\n",
    "    'External equity %': (x['EXTERNAL_EQUITY'].sum() / len(x)) * 100\n",
    "}))\n",
    "\n",
    "# Display the summary table\n",
    "print(summary_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
